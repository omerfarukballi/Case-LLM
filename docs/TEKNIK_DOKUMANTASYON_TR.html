<!DOCTYPE html>
<html lang="tr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Podcast Bilgi GrafiÄŸi - DetaylÄ± Teknik Mimari Raporu</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1000px;
            margin: auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }

        h1,
        h2,
        h3 {
            color: #2c3e50;
        }

        h1 {
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }

        .qa-box {
            background: #f9f9f9;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            border-left: 5px solid #3498db;
        }

        .qa-question {
            font-weight: bold;
            font-size: 1.2em;
            margin-bottom: 10px;
            color: #2980b9;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th,
        td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }

        th {
            background-color: #f2f2f2;
        }

        .mermaid {
            text-align: center;
            margin: 30px 0;
        }
    </style>
</head>

<body>

    <h1>Podcast Knowledge Graph: Teknik Mimari</h1>

    <div style="background:#e8f4f8; padding:20px; border-radius:10px; margin-bottom:30px;">
        <h3>ğŸš€ YÃ¶netici Ã–zeti (Executive Summary)</h3>
        <p>
            Bu proje, geleneksel RAG sistemlerinin yaÅŸadÄ±ÄŸÄ± "baÄŸlam kaybÄ±" ve "halÃ¼sinasyon" problemlerini Ã§Ã¶zmek iÃ§in
            geliÅŸtirilmiÅŸ, <strong>GraphRAG (Grafik TabanlÄ± Getirme)</strong> mimarisini kullanan bir yapay zeka
            sistemidir.
            <br><br>
            <strong>Temel Ä°novasyon:</strong> Veriyi sadece vektÃ¶r olarak deÄŸil, aynÄ± zamanda anlamsal iliÅŸkiler
            (Knowledge Graph) olarak saklar. Bu sayede <em>"Elon Musk'Ä±n bahsettiÄŸi kitaplar"</em> gibi karmaÅŸÄ±k
            iliÅŸkisel sorgulara %100 doÄŸrulukla cevap verirken, <em>"GiriÅŸimcilik hakkÄ±nda ne dÃ¼ÅŸÃ¼nÃ¼yor?"</em> gibi
            soyut sorgulara vektÃ¶r tabanlÄ± cevap verebilir.
            Sistem tamamen <strong>Local-First</strong> prensibiyle tasarlanmÄ±ÅŸtÄ±r; yani internete veya Cloud API'larÄ±na
            ihtiyaÃ§ duymadan, sÄ±fÄ±r maliyetle kullanÄ±cÄ±nÄ±n kendi donanÄ±mÄ± Ã¼zerinde Ã§alÄ±ÅŸÄ±r.
        </p>
    </div>

    <h2>Sistem Mimari ÅemasÄ±</h2>

    <div class="mermaid">
        graph TD
        subgraph Ingestion [1. Veri GiriÅŸi]
        A[YouTube URL] -->|yt-dlp| B(Ham Ses)
        B -->|FFmpeg| C(Optimize Ses)
        end
        subgraph Processing [2. Yerel Ä°ÅŸleme]
        C -->|Whisper Local| D[Transkripsiyon]
        D -->|Heuristic| E[Speaker Diarization]
        E -->|Window| F[Chunking]
        end
        subgraph Reasoning [3. AkÄ±l YÃ¼rÃ¼tme]
        F -->|Ollama| G[VarlÄ±k Ã‡Ä±karÄ±mÄ±]
        F -->|Nomic| H[VektÃ¶r Embedding]
        G -->|Levenshtein| I{Entity Resolution}
        end
        subgraph Storage [4. Depolama]
        I -->|Nodes/Edges| J[(Neo4j Graph)]
        H -->|Vectors| K[(ChromaDB)]
        end
        subgraph Retrieval [5. Sorgulama]
        L[Soru] -->|Router| M{Niyet?}
        M -->|Graph| N[Cypher]
        M -->|Vector| O[Similarity]
        N & O -->|Synthesis| P[LLM CevabÄ±]
        end
        style J fill:#3498db,stroke:#fff,color:#fff
        style K fill:#e67e22,stroke:#fff,color:#fff
        style G fill:#333,stroke:#fff,color:#fff
    </div>

    <h2>Teknik MÃ¼lakat SorularÄ± ve DetaylÄ± Cevaplar (Deep Dive)</h2>

    <div class="qa-box">
        <div class="qa-question">1. GraphDB YapÄ±sÄ±nÄ± NasÄ±l TasarladÄ±n?</div>
        <p><strong>Cevap:</strong> Graph yapÄ±sÄ±nÄ± tasarlarken sadece varlÄ±klarÄ± deÄŸil, semantik iliÅŸkileri de
            modellemeyi hedefledim. Basit bir 'Node-Link' yapÄ±sÄ± yerine zenginleÅŸtirilmiÅŸ (property-rich) bir ÅŸema
            (Schema-First Design) kurdum.</p>
        <ul>
            <li><strong>Nodes (DÃ¼ÄŸÃ¼mler):</strong> VarlÄ±klarÄ± kategorize ettim: `Person`, `Episode`, `Podcast`, `Topic`,
                `Company`, `Book`, `Movie`. Bu sayede sorgularda filtreleme (Ã¶rn: 'Sadece kitap tavsiyelerini getir')
                yapabiliyoruz, sorgu uzayÄ±nÄ± daraltÄ±p performansÄ± artÄ±rÄ±yoruz.</li>
            <li><strong>Edges (Ä°liÅŸkiler):</strong> Ä°liÅŸkileri eylem odaklÄ± tanÄ±mladÄ±m: `MENTIONED_IN`,
                `RECOMMENDED_BY`, `DISCUSSED`, `APPEARED_ON`. Ã–rneÄŸin, 'Tavsiye Etmek' ile 'Bahsetmek' arasÄ±ndaki farkÄ±
                modellemek, Ã¶neri sistemi (RecSys) iÃ§in kritiktir.</li>
            <li><strong>Strateji:</strong> Edge'lerin iÃ§ine metadata (Ã¶rneÄŸin: `timestamp`, `sentiment`, `context`)
                gÃ¶mdÃ¼m. BÃ¶ylece grafikte 'Elon Musk hangi bÃ¶lÃ¼mde geÃ§ti?' sorusuna deÄŸil, 'Elon Musk hangi bÃ¶lÃ¼mde
                olumlu bir baÄŸlamda geÃ§ti?' sorusuna bile tek bir Cypher sorgusuyla cevap verebiliyoruz.</li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">2. VectorDB YapÄ±sÄ±nÄ± NasÄ±l TasarladÄ±n? Chunk Stratejisi?</div>
        <p><strong>Cevap:</strong> VectorDB tarafÄ±nda RAG performansÄ±nÄ± artÄ±rmak iÃ§in Context-Aware Chunking stratejisi
            geliÅŸtirdim.</p>
        <ul>
            <li><strong>Chunk Stratejisi:</strong> Sabit boyutlu bÃ¶lme yerine, <strong>Overlapping Window</strong>
                (Kayar Pencere) kullandÄ±m.</li>
            <li><strong>Boyut:</strong> 2000 token (LLM'e yeterli baÄŸlam vermek iÃ§in). Overlap: 200 token (CÃ¼mleler
                bÃ¶lÃ¼nÃ¼rse anlam kaybÄ±nÄ± Ã¶nlemek iÃ§in).</li>
            <li><strong>Speaker Awareness:</strong> Chunk'larÄ± bÃ¶lerken konuÅŸmacÄ± deÄŸiÅŸim noktalarÄ±ndan bÃ¶lmeye
                Ã§alÄ±ÅŸtÄ±m. BÃ¶ylece bir chunk iÃ§inde konuÅŸmacÄ±nÄ±n sÃ¶zÃ¼nÃ¼n bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ korudum.</li>
            <li><strong>Metadata:</strong> Her vektÃ¶r chunk'Ä±na `video_id`, `speaker_name`, `timestamp` gibi metadatalar
                ekledim. Bu, 'Hybrid Search' yaparken vektÃ¶r aramasÄ±yla filtrelemeyi birleÅŸtirmemi saÄŸladÄ±.</li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">3. Diarization (KonuÅŸmacÄ± AyrÄ±mÄ±) NasÄ±l Ã‡Ã¶zeceksin?</div>
        <p><strong>Cevap:</strong> Diarization, bilgi grafiÄŸinin kalitesi iÃ§in kritik. Ä°ki aÅŸamalÄ± bir yaklaÅŸÄ±m
            benimsedim:</p>
        <ul>
            <li><strong>Akustik AyrÄ±ÅŸtÄ±rma:</strong> Maliyet ve gizlilik iÃ§in sisteme <strong>Local Whisper</strong>
                desteÄŸi ekledim. Whisper, ses deÄŸiÅŸim zamanlarÄ±nÄ± (timestamps) yakalar.</li>
            <li><strong>Heuristic Mapping:</strong> Akustik model 'Speaker A' Ã§Ä±ktÄ±sÄ± verir. Bunu gerÃ§ek isimlerle
                eÅŸleÅŸtirmek iÃ§in NLP heuristiÄŸi geliÅŸtirdim:
                <br>1. BÃ¶lÃ¼mÃ¼n baÅŸÄ±nda 'I am [Name]' diyen kiÅŸiyi Host olarak etiketle.
                <br>2. 'Welcome [Guest Name]' kalÄ±bÄ±ndan sonra konuÅŸan ilk yeni sesi Guest olarak etiketle.
            </li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">4. Embedding Modeli? Sebepleri?</div>
        <p><strong>Cevap:</strong> Model seÃ§iminde Performance/Cost Trade-off'una baktÄ±m:</p>
        <ul>
            <li><strong>SeÃ§im:</strong> `text-embedding-3-small` (OpenAI) veya Local mod iÃ§in `nomic-embed-text`.</li>
            <li><strong>Neden?</strong>
                <br>1. Boyut: 1536 vektÃ¶r boyutu, semantik arama iÃ§in yeterli yoÄŸunlukta (density).
                <br>2. Maliyet: 3-small Ã§ok ucuz ve MTEB skorlarÄ± eski ada-002'den yÃ¼ksek.
                <br>3. Local senaryoda nomic-embed-text tercih ettim Ã§Ã¼nkÃ¼ CPU Ã¼zerinde milisaniyeler iÃ§inde Ã§Ä±karÄ±m
                yapabiliyor ve uzun context (8k) destekliyor.
            </li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">5. Pre-processing ve Post-processing Stratejisi?</div>
        <p><strong>Cevap:</strong> Veri boru hattÄ±nÄ± modÃ¼ler tasarladÄ±m:</p>
        <ul>
            <li><strong>Pre-processing:</strong>
                <br>- Ses dosyasÄ±nÄ± FFmpeg ile 16kHz mono formata Ã§eviriyorum (Model baÅŸarÄ±sÄ±nÄ± artÄ±rÄ±r).
                <br>- VAD ile sessizlik kÄ±sÄ±mlarÄ±nÄ± atarak %20 token tasarrufu saÄŸlÄ±yorum.
            </li>
            <li><strong>Post-processing (Entity Resolution):</strong>
                <br>- LLM Ã§Ä±ktÄ±larÄ± tutarsÄ±z olabilir (Ã¶rn: 'Elon', 'Mr. Musk'). GrafiÄŸe yazmadan Ã¶nce Levenshtein
                mesafesi ile benzer isimleri tek node altÄ±nda birleÅŸtiriyorum (Deduplication).
                <br>- Hallucination kontrolÃ¼ iÃ§in confidence score filtresi ekledim (%70 altÄ± veri yazÄ±lmaz).
            </li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">6. Performans + Maliyet KaygÄ±larÄ±na Ã‡Ã¶zÃ¼mleriniz?</div>
        <p><strong>Cevap:</strong> Projenin en gÃ¼Ã§lÃ¼ yanÄ± bu mimari kararlar oldu:</p>
        <ul>
            <li><strong>Local processing:</strong> Local Whisper ve Local Ollama entegrasyonu ile operasyonel maliyeti
                (OpEx) sÄ±fÄ±ra indirdim ve veri gizliliÄŸini saÄŸladÄ±m.</li>
            <li><strong>Caching:</strong> L1 Cache (Dosya Hash) ve L2 Cache (Transkript JSON) kullanarak gereksiz
                iÅŸlemeyi Ã¶nledim.</li>
            <li><strong>Hybrid Search:</strong> Sadece VektÃ¶r aramasÄ± yerine, Ã¶nce Graph Cypher sorgusuyla adaylarÄ±
                daraltÄ±p, sonra vektÃ¶r aramasÄ± yaparak sorgu sÃ¼resini milisaniyelere indirdim.</li>
        </ul>
    </div>

    <h2>KapsamlÄ± UAT (KullanÄ±cÄ± Kabul Testi) SenaryolarÄ±</h2>
    <table>
        <thead>
            <tr>
                <th style="width:20%">Kategori</th>
                <th style="width:35%">Senaryo (KullanÄ±cÄ± Sorusu)</th>
                <th style="width:45%">Mimari Ã‡Ã¶zÃ¼m (Implementation)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>VarlÄ±k Filtreleme</strong></td>
                <td>"Steve Jobs <em>dÄ±ÅŸÄ±nda</em> Ã¶nerilen biyografiler?"</td>
                <td><strong>Graph Query:</strong>
                    <code>MATCH (p)-[:RECOMMENDED]->(b) WHERE NOT b.title CONTAINS 'Jobs'</code></td>
            </tr>
            <tr>
                <td><strong>Ã‡oklu VarlÄ±k</strong></td>
                <td>"Hem Elon Musk hem Naval'Ä±n Ã¶nerdiÄŸi kitaplar?"</td>
                <td><strong>Graph Intersection:</strong> Ä°ki dÃ¼ÄŸÃ¼mÃ¼n ortak komÅŸularÄ±nÄ± (Common Neighbors) bulur. O(1)
                    hÄ±zÄ±ndadÄ±r.</td>
            </tr>
            <tr>
                <td><strong>HalÃ¼sinasyon</strong></td>
                <td>"Lex, Satoshi ile rÃ¶portaj yaptÄ± mÄ±?"</td>
                <td><strong>Path Verification:</strong> VeritabanÄ±nda <code>(Lex)-[:APPEARED_ON]-(Satoshi)</code> yolu
                    yoksa, LLM'e sormadan 'HayÄ±r' dÃ¶ner.</td>
            </tr>
            <tr>
                <td><strong>Negatif Sorgu</strong></td>
                <td>"Hangi konuklar AI hakkÄ±nda <em>konuÅŸmadÄ±</em>?"</td>
                <td><strong>Exclusion Query:</strong> 'AI' konusuyla edgesi olmayan <code>Person</code> dÃ¼ÄŸÃ¼mlerini
                    getirir.</td>
            </tr>
            <tr>
                <td><strong>Zamansal</strong></td>
                <td>"2025'te 2028 OlimpiyatlarÄ± iÃ§in ne dendi?"</td>
                <td><strong>Metadata Filter:</strong> VektÃ¶r sorgusuna <code>$filter: {year: 2025}</code> eklenir.</td>
            </tr>
            <tr>
                <td><strong>Gizli Anlam (Implicit)</strong></td>
                <td>"Ä°sim vermeden kim PE eleÅŸtirisi yaptÄ±?"</td>
                <td><strong>Vector Search:</strong> 'Private Equity' kelimesi geÃ§mese bile 'misaligned incentives'
                    kavramÄ± vektÃ¶rel olarak eÅŸleÅŸir.</td>
            </tr>
            <tr>
                <td><strong>Ã‡atÄ±ÅŸma Analizi</strong></td>
                <td>"Chamath ve Friedberg hangi konuda anlaÅŸamadÄ±?"</td>
                <td><strong>Hybrid Search:</strong> Ã–nce grafikten ortak konular bulunur, sonra vektÃ¶rlerden
                    'disagreement' duygulu chunk'lar Ã§ekilir.</td>
            </tr>
            <tr>
                <td><strong>Kaynak KontrolÃ¼</strong></td>
                <td>"Sponsorlu olmayan saÄŸlÄ±k tavsiyeleri?"</td>
                <td><strong>Ad-Read Detection:</strong> 'promo code' geÃ§en kÄ±sÄ±mlar <code>is_ad=True</code> etiketlenir
                    ve sorguda elenir.</td>
            </tr>
        </tbody>
    </table>

    <!-- MERMAID SCRIPT (Guaranteed Placement) -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            securityLevel: 'loose',
        });
    </script>
</body>

</html>