<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Podcast Knowledge Graph - Technical Architecture Report</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1000px;
            margin: auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }

        h1,
        h2,
        h3 {
            color: #2c3e50;
        }

        h1 {
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }

        .qa-box {
            background: #f9f9f9;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            border-left: 5px solid #3498db;
        }

        .qa-question {
            font-weight: bold;
            font-size: 1.2em;
            margin-bottom: 10px;
            color: #2980b9;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th,
        td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }

        th {
            background-color: #f2f2f2;
        }

        .mermaid {
            text-align: center;
            margin: 30px 0;
        }
    </style>
</head>

<body>

    <h1>Podcast Knowledge Graph: Information Architecture</h1>

    <div style="background:#e8f4f8; padding:20px; border-radius:10px; margin-bottom:30px;">
        <h3>ðŸš€ Executive Summary</h3>
        <p>This system is a Local-First, GraphRAG-based AI solution that transforms unstructured podcast audio into a
            structured Knowledge Graph. It prioritizes privacy, zero API costs, and high-precision relational querying.
        </p>
    </div>

    <h2>System Architecture Diagram</h2>

    <div class="mermaid">
        graph TD
        subgraph Ingestion [1. Ingestion]
        A[YouTube URL] -->|yt-dlp| B(Raw Audio)
        B -->|FFmpeg| C(Optimized Audio)
        end
        subgraph Processing [2. Local Processing]
        C -->|Whisper Local| D[Transcription]
        D -->|Heuristic| E[Speaker Diarization]
        E -->|Window| F[Chunking]
        end
        subgraph Reasoning [3. Reasoning]
        F -->|Ollama| G[Entity Extraction]
        F -->|Nomic| H[Vector Embedding]
        G -->|Levenshtein| I{Entity Resolution}
        end
        subgraph Storage [4. Storage]
        I -->|Nodes/Edges| J[(Neo4j Graph)]
        H -->|Vectors| K[(ChromaDB)]
        end
        subgraph Retrieval [5. Retrieval]
        L[Query] -->|Router| M{Intent?}
        M -->|Graph| N[Cypher]
        M -->|Vector| O[Similarity]
        N & O -->|Synthesis| P[LLM Response]
        end
        style J fill:#3498db,stroke:#fff,color:#fff
        style K fill:#e67e22,stroke:#fff,color:#fff
        style G fill:#333,stroke:#fff,color:#fff
    </div>

    <h2>Technical Deep Dive (Interview Q&A)</h2>

    <div class="qa-box">
        <div class="qa-question">1. How did you design the GraphDB Structure?</div>
        <p><strong>Answer:</strong> "I aimed to model not just entities but semantic relationships. Instead of a simple
            'Node-Link' structure, I built a property-rich schema.</p>
        <ul>
            <li><strong>Nodes:</strong> Categorized entities into strict types: <code>Person</code>,
                <code>Episode</code>, <code>Podcast</code>, <code>Topic</code>, <code>Company</code>, <code>Book</code>,
                <code>Movie</code>. This allows filtering in queries (e.g., 'Fetch only book recommendations'), reducing
                search space.</li>
            <li><strong>Edges:</strong> Defined action-oriented relationships: <code>MENTIONED_IN</code>,
                <code>RECOMMENDED_BY</code>, <code>DISCUSSED</code>, <code>APPEARED_ON</code>. This distinction allows
                us to build a precise Recommendation System.</li>
            <li><strong>Strategy:</strong> Embedded metadata into edges (e.g., <code>timestamp</code>,
                <code>sentiment</code>, <code>context</code>). This allows us to answer not just 'Which episode did Elon
                appear in?', but 'In which episode did Elon appear in a positive context?'"</li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">2. How did you design the VectorDB & Chunking Strategy?</div>
        <p><strong>Answer:</strong> "To improve RAG performance, I developed a Context-Aware Chunking strategy.</p>
        <ul>
            <li><strong>Chunk Strategy:</strong> Instead of fixed-size splitting, I used an <strong>Overlapping
                    Window</strong> approach.</li>
            <li><strong>Size:</strong> 2000 tokens (to provide sufficient context to the LLM). Overlap: 200 tokens (to
                prevent loss of meaning at boundaries).</li>
            <li><strong>Speaker Awareness:</strong> I split chunks at speaker change points as much as possible,
                preserving the integrity of a speaker's turn.</li>
            <li><strong>Metadata:</strong> Added metadata like <code>video_id</code>, <code>speaker_name</code>,
                <code>timestamp</code> to every vector chunk. This enabled combining filtering with vector search during
                'Hybrid Search'."</li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">3. How did you solve Speaker Diarization?</div>
        <p><strong>Answer:</strong> "Diarization is critical for the graph quality. I adopted a two-staged approach:</p>
        <ul>
            <li><strong>Acoustic Separation:</strong> Originally used Cloud APIs, but switched to <strong>Local
                    Whisper</strong> for cost optimization and privacy. Whisper provides accurate timestamps for speaker
                turns.</li>
            <li><strong>Heuristic Mapping:</strong> The acoustic model outputs 'Speaker A'. I developed an NLP heuristic
                to map these to real names:
                <br>- Tag the person saying 'I am [Name]' at the start as Host.
                <br>- Tag the first new voice after 'Welcome [Guest Name]' as Guest.
            </li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">4. Embedding Model Choice? Reasons?</div>
        <p><strong>Answer:</strong> "I looked at the Performance/Cost Trade-off:</p>
        <ul>
            <li><strong>Choice:</strong> <code>text-embedding-3-small</code> (OpenAI) or <code>nomic-embed-text</code>
                for Local mode.</li>
            <li><strong>Why?</strong>
                <br>- Size: 1536 dimensions provide sufficient density for semantic search.
                <br>- Cost: 3-small is very cheap and has higher MTEB scores than the old ada-002.
                <br>- For Local scenarios, I prefer nomic-embed-text because it runs inference in milliseconds on CPU
                and supports long context (8k).
            </li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">5. Pre-processing and Post-processing Strategy?</div>
        <p><strong>Answer:</strong> "I designed a modular data pipeline:</p>
        <ul>
            <li><strong>Pre-processing (Cleaning):</strong>
                <br>- Convert audio to 16kHz mono using FFmpeg (improves model success).
                <br>- Remove unnecessary 'silence' segments via VAD to save tokens (~20%).
            </li>
            <li><strong>Post-processing (Entity Resolution):</strong>
                <br>- LLM outputs can be inconsistent (e.g., 'Elon Musk' vs 'Mr. Musk'). I applied a Entity Resolution
                step using Levenshtein distance to merge similar entities into a single node.
                <br>- Added a confidence score filter to check for 'Hallucinations' (discard entities below 70%)."
            </li>
        </ul>
    </div>

    <div class="qa-box">
        <div class="qa-question">6. Solutions for Performance + Cost Concerns?</div>
        <p><strong>Answer:</strong> "The project's strength lies in these architectural decisions:</p>
        <ul>
            <li><strong>Local Processing:</strong> Integrated Local Whisper and Local LLM (Mistral). This reduced OpEx
                to zero and ensured 100% data privacy.</li>
            <li><strong>Caching:</strong> Used L1 Cache (File Hash) and L2 Cache (Transcript JSON) to avoid redundant
                compute.</li>
            <li><strong>Hybrid Search:</strong> First narrow down candidates via Graph Cypher query, then perform vector
                search. This reduces query time from seconds to milliseconds.</li>
        </ul>
    </div>

    <h2>Comprehensive UAT (User Acceptance Test) Scenarios</h2>
    <table>
        <thead>
            <tr>
                <th style="width:20%">Category</th>
                <th style="width:35%">Scenario (User Query)</th>
                <th style="width:45%">Architectural Solution</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Entity Filtering</strong></td>
                <td>"Biographies recommended <em>excluding</em> Steve Jobs?"</td>
                <td><strong>Graph Query:</strong>
                    <code>MATCH (p)-[:RECOMMENDED]->(b) WHERE NOT b.title CONTAINS 'Jobs'</code></td>
            </tr>
            <tr>
                <td><strong>Multi-Entity</strong></td>
                <td>"Books recommended by both Elon and Naval?"</td>
                <td><strong>Graph Intersection:</strong> Finds common neighbor nodes of two Person nodes. O(1)
                    complexity.</td>
            </tr>
            <tr>
                <td><strong>Hallucination</strong></td>
                <td>"Did Lex interview Satoshi?"</td>
                <td><strong>Path Verification:</strong> If no <code>(Lex)-[:APPEARED_ON]-(Satoshi)</code> path exists,
                    return 'No' without LLM call.</td>
            </tr>
            <tr>
                <td><strong>Negative Query</strong></td>
                <td>"Which guests did <em>not</em> talk about AI?"</td>
                <td><strong>Exclusion Query:</strong> Fetches <code>Person</code> nodes with no edges to 'AI' topic.
                </td>
            </tr>
            <tr>
                <td><strong>Temporal</strong></td>
                <td>"What was said about 2028 Olympics in 2025?"</td>
                <td><strong>Metadata Filter:</strong> Vector query forced with <code>$filter: {year: 2025}</code>.</td>
            </tr>
            <tr>
                <td><strong>Implicit Meaning</strong></td>
                <td>"Who criticized PE without naming it?"</td>
                <td><strong>Vector Search:</strong> Matches concept vectors like 'misaligned incentives' even if keyword
                    is missing.</td>
            </tr>
            <tr>
                <td><strong>Conflict Analysis</strong></td>
                <td>"Disagreement between Chamath and Friedberg?"</td>
                <td><strong>Hybrid Search:</strong> Finds common topics in Graph, then searches for 'disagreement'
                    sentiment in Vectors.</td>
            </tr>
            <tr>
                <td><strong>Source Check</strong></td>
                <td>"Non-sponsored health advice?"</td>
                <td><strong>Ad-Read Detection:</strong> Segments with 'promo code' are tagged <code>is_ad=True</code>
                    and excluded.</td>
            </tr>
        </tbody>
    </table>

    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            securityLevel: 'loose',
        });
    </script>
</body>

</html>